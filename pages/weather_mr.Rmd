---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.15.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# Weather - Multiple Regression (Continued)

The data being used for this analysis are the Ward data set and the climate data from the [Met Office](https://www.metoffice.gov.uk/research/climate/maps-and-data/uk-climate-averages/gcpsvg3nc).

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

np.set_printoptions(precision=6)
import scipy.stats as sps
from scipy.optimize import minimize

from projtools.data import Data

data = Data()
idx = pd.IndexSlice
```

In the previous iteration of the multiple regression, we manually pasted in the data and constructed the dataframe using dictionaries.

In this version, we've downloaded all the data from the Heathrow station from the Met Office and structured and cleaned it.

We also added multiple indexing so it would matched the same indexing as the ward data set.

```{python}
# setup heathrow dataframe
df_heathrow = pd.DataFrame(pd.read_csv('../data/heathrow_48_23.csv'))

# format and filter year and month columns
df_heathrow = df_heathrow[(df_heathrow['year'] > 2010) & (df_heathrow['year'] < 2023)]
df_heathrow['month'] = df_heathrow['month'].astype(str).str.zfill(2)

# cast data types on columns
df_heathrow['year'] = df_heathrow['year'].astype(str)
df_heathrow['month'] = df_heathrow['month'].astype(str)
df_heathrow['tmax (degC)'] = pd.to_numeric(df_heathrow['tmax (degC)'], errors='raise')
df_heathrow['tmin (degC)'] = pd.to_numeric(df_heathrow['tmin (degC)'], errors='raise')
df_heathrow['af days'] = pd.to_numeric(df_heathrow['af days'], errors='raise')
df_heathrow['sun (hours)'] = pd.to_numeric(df_heathrow['sun (hours)'], errors='raise')

# set multiindex
df_heathrow.set_index(['year', 'month'], inplace=True)

# rename columns
df_heathrow.rename(
    columns={
        'tmax (degC)': 'tmax_degC',
        'tmin (degC)': 'tmin_degC', 
        'af days': 'airfrost_days',
        'rain (mm)': 'rain_mm', 
        'sun (hours)': 'sun_hours',
    },
    inplace=True)
```

### Estimated Daily Temperature


The Heathrow dataset doesn't provide us with any average daily temperature. However, it does provide a maximum and minimum average temperature for each month. Using this,we can create a simple estiamte for each month using.

$$
estimate\_daily\_temp = (max\_temp + min\_temp) / 2
$$

```{python}
df_heathrow['EstDailyTemp_degC'] = (df_heathrow['tmax_degC']+df_heathrow['tmin_degC']) / 2 
df_heathrow
```

## Multiple Regression


Do sunshine, rainfall, and temperature lead to a difference in dangerous driving?


**A priori hypothesis:**

Lower sunshine hours could increase dangerous driving offences as people are more likely to drive dangerously under the cover of darkness - this could potentially be during the winter months when there are fewer daylight hours.

Higher rainfall values could make drivers more cautious on the road and therefore decrease dangerous driving offences.

At the same time, they could also increase dangerous driving offences particularly for younger inexperienced drivers, as one study revealed that slippery roads due to poor weather pose a greater risk to young inexperienced drivers likely to exceed the speed limit [(Rolison and Moutari, 2020)](https://doi.org/10.1016/j.jsr.2020.02.017).

```{python}
crime = 'Dangerous Driving'
df_sun = df_heathrow['sun_hours'].groupby(level='month').agg('mean')
df_rain = df_heathrow['rain_mm'].groupby(level='month').agg('mean')
df_temp = df_heathrow['EstDailyTemp_degC'].groupby(level='month').agg('mean')
df_crime = data.borough.loc[idx[:,crime,:]].T.groupby(level='month').mean().T.mean()
```

### Function

```{python}
# code from notebook
def ss_two_predictors(bs_and_c, x1_vector, x2_vector, y_vector):
    """ Sum of squares error for intercept and a pair of slopes.
    """
    # unpack the list containing the slope and the intercept (this now has an extra slope!)
    b_1, b_2, c = bs_and_c 
    
    # calculate the fitted values, for this slope/intercept pairing (this now has an extra slope and extra vector!)
    fitted_vector = b_1*x1_vector + b_2*x2_vector + c 
    
    # calculate the error vector (this is the same process as for a single predictor)
    error = y_vector - fitted_vector
    
    # return the value of the cost function (this is the same process as for a single predictor)
    return np.sum(error ** 2)
```

```{python}
# code from notebook
def make_3d_scatter(x1, x2, y,
                    x1_slope,
                    x2_slope,
                    c, 
                   x1_label = 'x1',
                   x2_label = 'x2',
                   y_label = crime,
                   return_errors = True,
                   show = True,
                   plane_alpha = 0.5):
    sum_sq = ss_two_predictors([x1_slope, x2_slope, c], x1, x2, y)
    ax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')
    ax.scatter(x1,x2,y, label = 'Actual values ($y$)')
    ax.set_xlabel(x1_label)
    ax.set_ylabel(x2_label)
    ax.set_zlabel(y_label)
    mx_x1 = x1.max()
    mx_x2 = x2.max()
    mx_y = y.max()
    # Plot the fitting plane.
    plane_x = np.linspace(0, mx_x1, 50)
    plane_y = np.linspace(0, mx_x2, 50)
    X, Y = np.meshgrid(plane_x, plane_y)
    Z = c + x1_slope * X + x2_slope * Y
    ax.plot_wireframe(X,Y,Z, color = 'red', label = 'Linear regression plane', alpha = plane_alpha)
    ax.plot([], [], [],
        linestyle=':',
        linewidth=0.5,
        color='black',
        label = 'Errors ($ \\varepsilon $)')
    # Set the axis limits (and reverse y axis)
    ax.set_xlim(0, mx_x1)
    ax.set_ylim(0, mx_x2)
    ax.set_zlim(0, mx_y)
    ax.zaxis.labelpad=-3
    # show the legend
    plt.legend()
    plt.title(f"\n$b_1$ = {round(x1_slope,2)} \n$b_2$ = {round(x2_slope,2)} \n$c$ = {round(c,2)} \n Sum of Squared Error = {round(sum_sq, 2)}")
    if show == True:
        plt.show()
    if return_errors == True:
        fitted = c + x1_slope * x1 + x2_slope*x2
        errors = y - fitted
        return errors 

def plot_model_3D(x1_slope, x2_slope, c, return_errors = True):
    errors = make_3d_scatter(df_temp, df_sun, df_crime,
               x1_slope = x1_slope, 
               x2_slope = x2_slope,
               c = c,
               return_errors = return_errors)
    return errors
```

### Measures

```{python}
res_sun = sps.linregress(df_sun, df_crime)
res_rain = sps.linregress(df_rain, df_crime)
res_temp = sps.linregress(df_temp, df_crime)
```

```{python}
b_rain, c_rain = res_rain.slope, res_rain.intercept
b_sun, c_sun = res_sun.slope, res_sun.intercept
b_temp, c_temp = res_temp.slope, res_temp.intercept
```

```{python}
min_ss_rain_sun = minimize(
    ss_two_predictors,
    [b_rain, b_sun, c_sun],
    args=(df_rain, df_sun, df_crime)
)
min_ss_rain_sun.x
```

```{python}
min_ss_sun_temp = minimize(
    ss_two_predictors,
    [b_sun, b_temp, c_temp],
    args=(df_sun, df_temp, df_crime)
)

min_ss_sun_temp.x
```

```{python}
b_rain_rain_sun = min_ss_rain_sun.x[0]

b_sun_rain_sun = min_ss_rain_sun.x[1]

c_rain_sun = min_ss_rain_sun.x[2]
```

```{python}
b_sun_sun_temp = min_ss_sun_temp.x[0]

b_temp_sun_temp = min_ss_sun_temp.x[1]

c_sun_temp = min_ss_sun_temp.x[2]
```

## Graphing


### Plotting Sunshine and Temperature


$$
\vec{y} = b_1*\vec{x_1}+b_2*\vec{x_2} + c + \vec\epsilon
$$
$$
\vec{Dangerous\_Driving} = b_{sun}*\vec{sun}+b_{temp}*\vec{temp} + c + \vec\epsilon
$$


#### Exclusively Sunshine

```{python}
plot3d_sun_temp_only_sun = plot_model_3D(
    x1_slope = 0, # ignoring first predictor
    x2_slope = b_sun_sun_temp,
    c = c_sun_temp
)
```

```{python}
px.scatter(
    x = (df_sun*b_sun_sun_temp),
    y = df_crime,
    title = 'Sunlight only',
    labels = {'x': 'x2', 'y': 'Dangerous Driving'}
)
```

#### Exclusively Temperature

```{python}
plot3d_sum_temp_only_temp = plot_model_3D(
    x1_slope = b_temp_sun_temp,
    x2_slope = 0, # ignore the second predictor
    c = c_sun_temp
)
```

```{python}
px.scatter(
    x = (df_temp*b_temp_sun_temp),
    y = df_crime,
    title = 'Temperature only',
    labels = {'x': 'x1', 'y': 'Dangerous Driving'}
)
```

#### Combined Sunshine and Temperature

```{python}
plot3d_sum_temp_combined = plot_model_3D(
    x1_slope = b_temp_sun_temp, 
    x2_slope = b_sun_sun_temp,
    c = c_sun_temp
)
```

### Plotting Rainfall and Sunshine


$$
\vec{y} = b_1*\vec{x_1}+b_2*\vec{x_2} + c + \vec\epsilon
$$
$$
\vec{Dangerous\_Driving} = b_{rain}*\vec{rain}+b_{sun}*\vec{sun} + c + \vec\epsilon
$$


#### Exclusively Rainfall

```{python}
plot3d_rain_sun_only_rain = plot_model_3D(
    x1_slope = 0, # ignoring first predictor
    x2_slope = b_rain_rain_sun,
    c = c_rain_sun
)
```

```{python}
px.scatter(
    x = (df_rain*b_rain_rain_sun),
    y = df_crime,
    title = 'Rainfall only',
    labels = {'x': 'x2', 'y': 'Dangerous Driving'}
)
```

#### Exclusively Sunshine

```{python}
plot3d_rain_sun_only_sun = plot_model_3D(
    x1_slope = b_sun_rain_sun,
    x2_slope = 0, # ignore the second predictor
    c = c_rain_sun
)
```

```{python}
px.scatter(
    x = (df_sun*b_sun_rain_sun),
    y = df_crime,
    title = 'Sunshine only',
    labels = {'x': 'x2', 'y': 'Dangerous Driving'}
)
```

#### Combined Sunshine and Rainfall

```{python}
plot3d_rain_sun_combined = plot_model_3D(
    x1_slope = b_rain_rain_sun, 
    x2_slope = b_sun_rain_sun,
    c = c_rain_sun
)
```

## Conclusion


Before concluding, we are testing to see if the model is good at predicting dangerous driving crimes by calculating the $R^2$ value.


$$
R^2 = 1-{SS_{residual}\over SS_{mean}}
$$


$SS_{residual}$ is:

$$
SS_{residual} = {1\over n}\Sigma_{i=1}^{n}{(y-\hat{y})^2}
$$

Where $\hat{y}$ is the y predictor value.

$SS_{mean}$ is:

$$
SS_{mean} = {1\over n}\Sigma_{i=1}^{n}{(y-\bar{y})^2}
$$

```{python}
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

regressor = LinearRegression()
```

```{python}
df_danger_drive = pd.DataFrame(
    [df_rain, df_sun, df_temp, df_crime],
    index = ['Rainfall', 'Sunshine', 'Temperature', 'Crime']
    ).T
```

**Note:** 

Initally the X and Y values for this test were produced using:

```py
X = df_danger_drive[['Rainfall', 'Sunshine', 'Temperature']]
Y = df_danger_drive['Crime']
```

Using these values produced a negative $R^2$, potentially due to the aggregated data in the dataframes. Ideally the $R^2$ value should be between 0 and 1, however, a negative suggests that the model is not a good fit for the data and is performing worse than a model that simply predicts the mean of the dependant variables. It's possible that the data used to train and test the model is the source of this problem.

The X and Y values produced below produced a positve R value, which has been adopted in the conclusion of this study.

```{python}
X = pd.DataFrame(
    [
        df_heathrow['sun_hours'], 
        df_heathrow['rain_mm'], 
        df_heathrow['EstDailyTemp_degC']
    ],
).T
```

```{python}
Y = data.borough.T \
    .loc['2011':'2022']\
        ['Miscellaneous Crimes Against Society']\
            ['Dangerous Driving'].T.sum()
```

```{python}
X_train, X_test, Y_train, Y_test = train_test_split(
    X, 
    Y, 
    test_size=0.2, 
    random_state=0
    )
```

```{python}
regressor.fit(X_train, Y_train)
y_pred = regressor.predict(X_test)
```

```{python}
# Calculate R-squared value
r2 = r2_score(Y_test, y_pred)
print("R-squared value:", r2)
```

The $R^2$ value produced here is `0.02729`, which suggests that the model explains approximately 2.73% of the variance in the dependent variable; being only slightly better than if we just guessed using the average of the actual results.


# Bibliography


{bibliography}
